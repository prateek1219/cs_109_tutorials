{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline #put plots here not is separate window\n",
    "\n",
    "import pandas as pd # to handle data as dataframes\n",
    "import scipy as sp #import statistics methods and scientific computing\n",
    "import numpy as np #import numerical computing\n",
    "from pandas import DataFrame, Series\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt #sets up plotting under plt\n",
    "import seaborn as sns #sets up styles and gives us more plotting options\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.width',500)\n",
    "pd.set_option('display.max_columns',100)\n",
    "\n",
    "#this is just practicing movielens dataset analysis using pandas \n",
    "##original content: http://www.gregreda.com/2013/10/26/working-with-pandas-dataframes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "cur_dir = subprocess.check_output([\"pwd\"]) #to run bash/shell commands\n",
    "cur_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filepath = str(cur_dir).strip()+'/mariano-rivera.csv' #this can be a url as well\n",
    "from_csv = pd.read_csv(csv_filepath,header=None,error_bad_lines=False, sep=',')\n",
    "from_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll be using the MovieLens dataset in many examples going forward. \n",
    "#The dataset contains 100,000 ratings made by 943 users on 1,682 movies\n",
    "\n",
    "# pass in column names for each CSV\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv(str(cur_dir).strip()+'/ml-100k/u.user', sep='|', names=u_cols,encoding='latin-1')\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(str(cur_dir).strip()+'/ml-100k/u.data', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first five columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "movies = pd.read_csv(str(cur_dir).strip()+'/ml-100k/u.item', sep='|', names=m_cols, usecols=range(5), encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()\n",
    "print users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some data inspection\n",
    "movies.head()\n",
    "movies.info() #gives how many cells have Null values \n",
    "movies.dtypes\n",
    "users.describe() #gives statistics about means and spread\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[['age','zip_code']].head() #column selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row selection\n",
    "print(users[users.age > 25].head(3))\n",
    "print('\\n')\n",
    "\n",
    "# users aged 40 AND male\n",
    "print(users[(users.age == 40) & (users.sex == 'M')].head(3))\n",
    "print('\\n')\n",
    "\n",
    "# users younger than 30 OR female\n",
    "print(users[(users.sex == 'F') | (users.age < 30)].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.set_index('user_id', inplace=True) #setting index to user_id column, modification is inplace\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#once index is set to numerical value we can use iloc to get the row\n",
    "users.iloc[[1,2,3]] #iloc starts from index 0\n",
    "#we can select directly by label (i.e. index name/val) using loc method\n",
    "users.loc[[1,2,3]] #here label is user_id/index value\n",
    "\n",
    "#u can use df.reset_index(inplace=True) to reset index label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL JOIN operation\n",
    "#how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
    "#left: use only keys from left frame (SQL: left outer join)\n",
    "#right: use only keys from right frame (SQL: right outer join)\n",
    "#outer: use union of keys from both frames (SQL: full outer join)\n",
    "#inner: use intersection of keys from both frames (SQL: inner join)\n",
    "\n",
    "#Fills NA if the key is not present in join\n",
    "\n",
    "pd.merge(left_frame, right_frame, left_on='left_key', right_on='right_key',how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppose if you want to process excel sheet while creating df, you can do by using converters in read_csv function\n",
    "headers = ['name', 'title', 'department', 'salary']\n",
    "#converters_dict = {'name': lambda x: x + ' prateek', 'salary': lambda x: float(x.replace('$', ''))}\n",
    "converters_dict = {'salary': lambda x: float(x.replace('$', ''))}\n",
    "csv_filepath = str(cur_dir).strip()+'/city-of-chicago-salaries.csv'\n",
    "chicago = pd.read_csv(csv_filepath, \n",
    "                      header=0,\n",
    "                      names=headers,\n",
    "                      converters=converters_dict)\n",
    "#here salary column has '$' in every entry, it will be replaced by '' when df is populated\n",
    "#chicago.head()\n",
    "\n",
    "#lets analyze the chicago salary data for each department\n",
    "#first group it by dept\n",
    "by_dept = chicago.groupby('department')\n",
    "by_dept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have data grouped by department values\n",
    "#count number of employees in each department\n",
    "by_dept.count().head()['name'] #num employees in each dept\n",
    "by_dept.count() #count for each department i.e. number of not NULL records\n",
    "by_dept.size().tail() # total records for each department\n",
    "by_dept.sum() #total salary of each department\n",
    "by_dept.mean() #avg salary of each dept\n",
    "by_dept.median() #median salary of each dept\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find top five departments with most distinct titles\n",
    "by_dept['title'].nunique().sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find highest paid employee in each department\n",
    "#first sort salaries in df\n",
    "chicago.sort_values('salary', ascending=False, inplace=True)\n",
    "salary_sorted_dept = chicago.groupby('department') #then group by dept\n",
    "for name,group in salary_sorted_dept:\n",
    "        print group.iloc[0] #first entry will be highest salary person\n",
    "        print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print all employees from law department with just name and salary\n",
    "chicago[chicago.department=='LAW'][['name','salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start to analyze movie dataset\n",
    "#first we merge all datasets to get single df; movies; users; ratings\n",
    "# we have already merged all separate df to get lens df\n",
    "\n",
    "#DF is a group of series (columns) each sharing an index/header (col_name)\n",
    "#print users.head(2)\n",
    "users['user_id'] = users.index\n",
    "\n",
    "movie_ratings = pd.merge(users, ratings)\n",
    "lens = pd.merge(movie_ratings, movies)\n",
    "\n",
    "lens.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get 25 most rated movies\n",
    "\n",
    "\n",
    "most_rated = lens.groupby('title')\n",
    "#print most_rated.title.head()\n",
    "test=   most_rated.title.count() #count numElem in all groups and return as series\n",
    "print test.sort_values(ascending=False)[:25]\n",
    "\n",
    "#OneLine\n",
    "lens.title.value_counts()[:25] #counts the frequency of each title and sort it; so get top 25 then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find top 25 movies which have highest rating_value with atleast 100 ratings\n",
    "df1 = lens.groupby('title').agg({'rating':[np.size,np.mean]}) # this split and then apply agg function\n",
    "                                                              #to get some stats for each grp\n",
    "df1 = df1[df1['rating']['size']>=100]#now get size>=100\n",
    "df1.sort_values([('rating', 'mean')], ascending=False)[:15] #Additionally, because our columns are now a MultiIndex, \n",
    "#we need to pass in a tuple specifying how to sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find 50 most rated movies\n",
    "#OneLine\n",
    "most_50 = lens.title.value_counts()[:50] #counts the frequency of each title and sort it; so get top 25 then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by age find out the mean rating given by users; age_group 0-10, 11-20 etc\n",
    "#use pd.cut function to put data in bins\n",
    "labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79'] #create bins\n",
    "lens['age_group'] = pd.cut(lens.age,range(0,81,10),right=False,labels=labels)\n",
    "age_grp = lens.groupby('age_group').agg({'rating':[np.mean,np.size]})\n",
    "age_grp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mean rating for each age group for most_50 rated movies\n",
    "most_50 = lens.title.value_counts()[:50] #get the series/array for most 50 watched movies; \n",
    "#here index will be title names\n",
    "\n",
    "lens.set_index(lens.title,inplace=True) #get the dataframe for most 50 watched movies from orig df\n",
    "#by first setting the index for orig df to the index of the series captured\n",
    "\n",
    "#lens.head()\n",
    "#most_50.index\n",
    "\n",
    "df2 = lens.loc[most_50.index] #df for 50 most watched movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get the agg stats for age label and all\n",
    "#since age group column is already there we groupby title and age_group\n",
    "#otherwise create age grp columns\n",
    "#labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79'] #create bins\n",
    "#lens['age_group'] = pd.cut(lens.age,range(0,81,10),right=False,labels=labels)\n",
    "\n",
    "\n",
    "grouped = df2.groupby([df2.title,'age_group']).agg({'rating':[np.mean]}) #now we have groups for each movie with all age ranges\n",
    "#grouped.rating.mean()[:15]\n",
    "grouped.head() # for bigger display vertically takes a lot of lines\n",
    "grouped.unstack().fillna(0)[:5] #displays in the form of a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivot Tables tutorial\n",
    "pd.pivot_table(lens,index=lens.title) #gives pivot table with index as string and all other numerical data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = pd.pivot_table(lens,index=[lens.title,'sex']) # two index, sex and title, for each title it gives avg stats for female and male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want statistics for particular things like movie rating u mention that in columns field in pivot\n",
    "#pivoted = pd.pivot_table(lens,index=[lens.title],values=['rating']) #by def aggfunc is np.mean \n",
    "\n",
    "#but you can give a dict here\n",
    "#pivoted = pd.pivot_table(lens,index=[lens.title,'sex'],values=['rating'],aggfunc={'rating':np.mean})\n",
    "\n",
    "pivoted = lens.pivot_table(index=['movie_id',lens.title],\n",
    "                         columns='sex',\n",
    "                         values='rating',\n",
    "                         aggfunc={'rating':np.mean}, #[np.mean,len]\n",
    "                         fill_value=0)\n",
    "pivoted = lens.pivot_table(index=['movie_id', 'title'],\n",
    "                           columns=['sex'],\n",
    "                           values='rating',\n",
    "                           fill_value=0)\n",
    "#Since we wanted to see rating broken down by gender, the columns variable allows us to define one or more columns.\n",
    "#Columns vs. Values\n",
    "#I think one of the confusing points with the pivot_table is the use of columns and values . \n",
    "#Remember, columns are optional - they provide an additional way to segment the actual values you care about. \n",
    "#he aggregation functions are applied to the values you list.\n",
    "\n",
    "\n",
    "pivoted['diff'] = pivoted.M - pivoted.F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_50 = lens.groupby('movie_id').size().sort_values(ascending=False)[:50]\n",
    "disagreements = pivoted[pivoted.movie_id.isin(most_50.index)]['diff'] #check if the index is in top_50 movie and get ['diff'] for them\n",
    "disagreements.sort_values().plot(kind='barh', figsize=[9, 15]) #sort and plot\n",
    "\n",
    "plt.title('Male vs. Female Avg. Ratings\\n(Difference > 0 = Favored by Men)')\n",
    "plt.ylabel('Title')\n",
    "plt.xlabel('Average Rating Difference');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#analysis is completed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
